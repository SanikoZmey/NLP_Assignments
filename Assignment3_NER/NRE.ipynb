{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Alexander Kurdyukov BS21-AI-01`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For training the toc2vec model [ru_core_news_lg](https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.7.0/ru_core_news_lg-3.7.0-py3-none-any.whl) vectors were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download ru_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing needed packages and loading the HuggingFace dataset to use its part as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ario\\miniconda3\\envs\\InfoRetr\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Ario\\miniconda3\\envs\\InfoRetr\\lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for MalakhovIlya/RuNNE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/MalakhovIlya/RuNNE\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "spacy.require_gpu()\n",
    "\n",
    "dataset = load_dataset('MalakhovIlya/RuNNE', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "\n",
    "def get_spacy_doc(data):\n",
    "  ### Create a blank spaCy pipeline\n",
    "  nlp = spacy.blank('ru')\n",
    "  \n",
    "  ### Create DocBin object to store processed texts\n",
    "  db = DocBin()\n",
    "\n",
    "  ### Some counters for statistics\n",
    "  counter_all, counter_filt, counter_ign = 0, 0, 0\n",
    "\n",
    "  ### Iterate through the data\n",
    "  for line in tqdm(data):\n",
    "    doc = nlp.make_doc(line[\"sentences\"])\n",
    "    annot = line['ners']\n",
    "    ents = []\n",
    "\n",
    "    ### Extract entities from the annotations\n",
    "    for start, end, label in annot:\n",
    "      start, end = int(start), int(end)\n",
    "      try:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
    "        ### Some other attempts to get character span(due to the broken positionings)\n",
    "        if span is None:\n",
    "          span = doc.char_span(start, end + 1, label=label, alignment_mode='strict')\n",
    "        if span is None:\n",
    "          span = doc.char_span(start - 1, end, label=label, alignment_mode='strict')\n",
    "      except:\n",
    "        continue\n",
    "\n",
    "      if span is None:\n",
    "        ### Log errors for annotations that couldn't be processed\n",
    "        # print(str(line[\"sentences\"])[start: end], doc.char_span(start, end, label=label, alignment_mode='expand'), label)\n",
    "        counter_ign += 1\n",
    "      else:\n",
    "        ents.append(span)\n",
    "      counter_all += 1\n",
    "    \n",
    "    try:\n",
    "      ### Filtering overlapping and repeating spans and then saving the text and NER-data\n",
    "      filtered_ents = spacy.util.filter_spans(ents)\n",
    "      doc.ents = filtered_ents\n",
    "      counter_filt += len(filtered_ents)\n",
    "      db.add(doc)\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  ### Printing some global statistics about the spans \n",
    "  print(counter_all, counter_filt, counter_ign)\n",
    "  return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the train and test data with some formatting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/train.jsonl') as f:\n",
    "    c_train_data = [json.loads(line) for line in f]\n",
    "\n",
    "test_data = [{\"sentences\": dataset['test'][\"text\"][line_id], \"ners\": [triple.split() for triple in dataset['test'][\"entities\"][line_id]]} for line_id in range(len(dataset['test']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing all the data and creating data files for spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ario\\miniconda3\\envs\\InfoRetr\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\Ario\\miniconda3\\envs\\InfoRetr\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "100%|██████████| 519/519 [00:04<00:00, 129.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30835 23963 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:00<00:00, 94.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5843 4605 30\n"
     ]
    }
   ],
   "source": [
    "train_db = get_spacy_doc(c_train_data)\n",
    "test_db = get_spacy_doc(test_data)\n",
    "\n",
    "train_db.to_disk(\"train_data.spacy\")\n",
    "test_db.to_disk(\"test_data.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tok2Vec model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config_tok2vec.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_tok2vec.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ario\\miniconda3\\envs\\InfoRetr\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\Ario\\miniconda3\\envs\\InfoRetr\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config_tok2vec.cfg config_tok2vec.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainging tok2vec model for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00    152.76    1.35    0.79    4.47    0.01\n",
      "  0     200       1520.60  14922.71   35.70   44.67   29.73    0.36\n",
      "  0     400        865.26  10227.36   48.55   55.14   43.37    0.49\n",
      "  1     600       2546.01   9514.24   54.63   56.90   52.53    0.55\n",
      "  1     800       1346.13   8012.11   58.46   59.16   57.79    0.58\n",
      "  1    1000        409.76   8081.77   59.36   61.95   56.98    0.59\n",
      "  2    1200       2882.65   6674.63   59.97   66.33   54.72    0.60\n",
      "  2    1400        460.32   6540.27   59.80   64.96   55.40    0.60\n",
      "  3    1600       2920.95   6228.43   62.03   64.65   59.61    0.62\n",
      "  3    1800        478.41   4840.11   62.15   65.12   59.44    0.62\n",
      "  3    2000        565.17   5558.58   63.11   67.33   59.39    0.63\n",
      "  4    2200        506.39   4593.23   62.52   68.31   57.63    0.63\n",
      "  4    2400        770.70   4502.85   63.08   65.08   61.19    0.63\n",
      "  5    2600        593.10   4518.56   63.52   65.06   62.04    0.64\n",
      "  5    2800        671.53   3907.86   63.33   64.26   62.43    0.63\n",
      "  5    3000        589.19   3766.04   63.18   64.03   62.35    0.63\n",
      "  6    3200        619.02   3292.94   62.71   65.29   60.33    0.63\n",
      "  6    3400        696.73   3381.12   63.00   65.95   60.30    0.63\n",
      "  6    3600        689.05   3274.63   65.15   69.02   61.69    0.65\n",
      "  7    3800        572.86   2763.00   63.71   67.34   60.46    0.64\n",
      "  7    4000        659.15   2934.37   64.66   66.53   62.89    0.65\n",
      "  8    4200        605.12   2829.25   64.27   63.43   65.12    0.64\n",
      "  8    4400        579.74   2371.28   63.40   65.89   61.09    0.63\n",
      "  8    4600        583.90   2555.48   64.32   66.15   62.58    0.64\n",
      "  9    4800       1396.40   2274.12   64.05   66.22   62.02    0.64\n",
      "  9    5000       5905.93   2572.69   63.76   65.99   61.67    0.64\n",
      " 10    5200        658.34   2311.57   64.32   67.20   61.67    0.64\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ario\\miniconda3\\envs\\InfoRetr\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\Ario\\miniconda3\\envs\\InfoRetr\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train --gpu-id 0 config_tok2vec.cfg --output ./ --paths.train ./train_data.spacy --paths.dev ./test_data.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy init fill-config base_config_trans.cfg config_trans.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainging transformer model for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ario\\miniconda3\\envs\\InfoRetr\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\Ario\\miniconda3\\envs\\InfoRetr\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0         808.42    820.40    0.12    0.08    0.26    0.00\n",
      "  2     200      806782.36  173838.81   37.19   62.23   26.51    0.37\n",
      "  5     400       89629.25  58944.69   73.55   73.83   73.27    0.74\n",
      "  7     600       20693.63  33460.93   77.81   77.16   78.48    0.78\n",
      " 10     800        7900.66  23606.74   78.06   77.68   78.44    0.78\n",
      " 12    1000        5990.45  19744.57   78.06   75.80   80.46    0.78\n",
      " 15    1200        2786.91  17490.43   78.31   76.53   80.17    0.78\n",
      " 17    1400        2571.47  16501.79   77.54   75.10   80.15    0.78\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train --gpu-id 0 config_trans.cfg --output ./ --paths.train ./train_data.spacy --paths.dev ./test_data.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and testing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok2vec_model = spacy.load(\"model-best\")\n",
    "transformer_model = spacy.load(\"prev_best_trans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('data/dev.jsonl') as f:\n",
    "    dev_data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model on sentences from the set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мать Майкла Джексона PERSON\n",
      "на несколько дней DATE\n",
      "Мать PERSON\n",
      "в 2009 году DATE\n",
      "Майкла Джексона Кэтрин PERSON\n",
      "две недели назад DATE\n",
      "через десять дней DATE\n",
      "РИА Новости ORGANIZATION\n",
      "Ассошиэйтед Пресс ORGANIZATION\n",
      "Кэтрин PERSON\n",
      "троих NUMBER\n",
      "Майкла Джексона PERSON\n",
      "Ранее, 22 июля DATE\n",
      "представитель Кэтрин PROFESSION\n",
      "Джексон PERSON\n",
      "полицию Калифорни ORGANIZATION\n",
      "Жермен Джексон PERSON\n",
      "врачи PROFESSION\n",
      "82-летней AGE\n",
      "Ребби PERSON\n",
      "Аризона STATE_OR_PROVINCE\n",
      "Через четыре дня DATE\n",
      "суд Калифорнии ORGANIZATION\n",
      "лишил EVENT\n",
      "Кэтрин CITY\n",
      "Принс ORGANIZATION\n",
      "Пэрис NATIONALITY\n",
      "в течение десяти дней DATE\n",
      "34-летний AGE\n",
      "TJ ORGANIZATION\n",
      "Тито Джексона PERSON\n",
      "певцу старшим PROFESSION\n",
      "в четверг DATE\n",
      "Кэтрин CITY\n",
      "Майкла Джексона PERSON\n",
      "доктор PROFESSION\n",
      "Тусон CITY\n",
      "Аризона STATE_OR_PROVINCE\n",
      "певца PROFESSION\n",
      "Кэтрин LOCATION\n",
      "полицию Калифорнии ORGANIZATION\n",
      "Кэтрин CITY\n",
      "Принс PERSON\n",
      "Пэрис COUNTRY\n",
      "Блэнкет PERSON\n",
      "Кэтрин PERSON\n",
      "скандал EVENT\n",
      "Майкла Джексона PERSON\n",
      "Кэтрин WORK_OF_ART\n",
      "певца PROFESSION\n",
      "Джексона PERSON\n",
      "В минувшую среду DATE\n",
      "Ассошиэйтед Пресс ORGANIZATION\n",
      "Кэтрин PERSON\n",
      "Жермен Джексон PERSON\n",
      "Майкл Джексон PERSON\n",
      "скончался EVENT\n",
      "25 июня 2009 года DATE\n",
      "на 51-м году AGE\n",
      "передозировки сильнодействующими снотворными препаратами DISEASE\n"
     ]
    }
   ],
   "source": [
    "text = dev_data[18]['senences']\n",
    "# print(text)\n",
    "\n",
    "out = tok2vec_model(text)\n",
    "for ent in out.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Майкла Джексона PERSON\n",
      "на несколько дней DATE\n",
      "скончавшегося EVENT\n",
      "в 2009 году DATE\n",
      "короля поп-музыки PROFESSION\n",
      "Майкла Джексона PERSON\n",
      "Кэтрин PERSON\n",
      "две недели назад DATE\n",
      "пропала DISEASE\n",
      "через десять дней DATE\n",
      "РИА Новости ORGANIZATION\n",
      "Ассошиэйтед Пресс ORGANIZATION\n",
      "Кэтрин PERSON\n",
      "троих NUMBER\n",
      "Майкла Джексона PERSON\n",
      "22 июля DATE\n",
      "представитель PROFESSION\n",
      "Кэтрин Джексон PERSON\n",
      "полицию Калифорни ORGANIZATION\n",
      "короля поп-музыки PROFESSION\n",
      "Жермен Джексон PERSON\n",
      "врачи PROFESSION\n",
      "82-летней AGE\n",
      "Аризона STATE_OR_PROVINCE\n",
      "Через четыре дня DATE\n",
      "суд Калифорнии ORGANIZATION\n",
      "лишил EVENT\n",
      "Кэтрин PERSON\n",
      "Блэнкет PERSON\n",
      "Принс PERSON\n",
      "Пэрис PERSON\n",
      "в течение десяти дней DATE\n",
      "временным опекуном детей PROFESSION\n",
      "34-летний AGE\n",
      "ТиДжей PERSON\n",
      "TJ ORGANIZATION\n",
      "Тито Джексона PERSON\n",
      "певцу PROFESSION\n",
      "Накануне DATE\n",
      "в четверг DATE\n",
      "Кэтрин PERSON\n",
      "Майкла Джексона PERSON\n",
      "доктор PROFESSION\n",
      "Тусон CITY\n",
      "Аризона STATE_OR_PROVINCE\n",
      "певца PROFESSION\n",
      "США COUNTRY\n",
      "Кэтрин PERSON\n",
      "одним утром TIME\n",
      "полицию Калифорнии ORGANIZATION\n",
      "Тусоне DISTRICT\n",
      "Кэтрин PERSON\n",
      "Принс PERSON\n",
      "Пэрис PERSON\n",
      "Блэнкет PERSON\n",
      "Кэтрин PERSON\n",
      "Майкла Джексона PERSON\n",
      "Кэтрин PERSON\n",
      "певца PROFESSION\n",
      "завещание EVENT\n",
      "Джексона PERSON\n",
      "поддельное DATE\n",
      "В минувшую среду DATE\n",
      "Ассошиэйтед Пресс ORGANIZATION\n",
      "Кэтрин Жермен Джексон PERSON\n",
      "подписал это письмо EVENT\n",
      "поп-короля PROFESSION\n",
      "Майкл Джексон PERSON\n",
      "скончался EVENT\n",
      "25 июня 2009 года DATE\n",
      "на 51-м году AGE\n",
      "передозировки сильнодействующими снотворными препаратами DISEASE\n"
     ]
    }
   ],
   "source": [
    "text = dev_data[18]['senences']\n",
    "# print(text)\n",
    "\n",
    "out = transformer_model(text)\n",
    "for ent in out.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model to get NERS from all the sentences of the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:04<00:00, 14.21it/s]\n"
     ]
    }
   ],
   "source": [
    "out_data = []\n",
    "for line in tqdm(dev_data, total=len(dev_data)):\n",
    "    out = transformer_model(line[\"senences\"])\n",
    "    ents = []\n",
    "    for ent in out.ents:\n",
    "        ents.append([ent.start_char, ent.end_char, ent.label_])\n",
    "    out_data.append({\"id\":line[\"id\"], \"ners\": ents})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results in `test.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.jsonl\", 'w') as f:\n",
    "    for item in out_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('test.jsonl') as f:\n",
    "#     data = [json.loads(line) for line in f]\n",
    "\n",
    "# data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "InfoRetr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
